{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains a NeRF using perspective projection and then renders out images using orthographic projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from dataset import diff_rendering_dataset\n",
    "from rendering import VolumeRenderer\n",
    "from fields import RadianceField\n",
    "from training import fit_inverse_graphics_representation\n",
    "from utils import to_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data_path = \"./data/bunny\"\n",
    "cam2world = np.load(os.path.join(data_path, \"cam2world.npy\"))\n",
    "images = np.load(os.path.join(data_path, \"images.npy\"))\n",
    "\n",
    "cam2world = torch.Tensor(cam2world).to(device)\n",
    "images = torch.tensor(images).to(device)\n",
    "intrinsics = torch.tensor([[0.7, 0.0, 0.5],\n",
    "                            [0.0, 0.7, 0.5],\n",
    "                            [0.0, 0.0, 1.0]]).to(device)\n",
    "print(cam2world.shape, images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "\n",
    "bunny_dataset = diff_rendering_dataset(images, cam2world, device=device)\n",
    "model_input, gt = next(bunny_dataset)\n",
    "\n",
    "plt.imshow(gt.view(images.shape[1], images.shape[2], 3).detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "radiance_field = RadianceField(scene_rep_name=\"HybridVoxelNeuralField\", device=device).to(device)\n",
    "renderer = VolumeRenderer(near=1.5, far=4.5, n_samples=128, white_back=True, rand=False).to(device)\n",
    "img_resolution = (128, 128, 3)\n",
    "fit_inverse_graphics_representation(\n",
    "    representation=radiance_field,\n",
    "    renderer=renderer,\n",
    "    data_iter=bunny_dataset,\n",
    "    img_resolution=img_resolution,\n",
    "    lr=1e-3,\n",
    "    total_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render both perspective and orthographic images\n",
    "\n",
    "orthographic_renderer = VolumeRenderer(\n",
    "    near=1.5, far=4.5, n_samples=128, white_back=True, rand=False, orthographic=True\n",
    ").to(device)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12), squeeze=False)\n",
    "\n",
    "num_images = 3\n",
    "for i in range(num_images):\n",
    "    # Get next camera params\n",
    "    cam_params, _ = next(bunny_dataset)\n",
    "    cam_params = to_gpu(cam_params)\n",
    "\n",
    "    # Render image with both perspective and orthographic projection\n",
    "    rgb, _ = renderer(cam_params, radiance_field)\n",
    "    orthographic_rgb, _ = orthographic_renderer(cam_params, radiance_field)\n",
    "    \n",
    "    axes[0, i].imshow(rgb.cpu().view(*img_resolution).detach().numpy())\n",
    "    axes[0, i].set_axis_off()\n",
    "    axes[0, i].set_title(f\"Perspective {i}\")\n",
    "\n",
    "    axes[1, i].imshow(orthographic_rgb.cpu().view(*img_resolution).detach().numpy())\n",
    "    axes[1, i].set_axis_off()\n",
    "    axes[1, i].set_title(f\"Orthographic {i}\")\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
